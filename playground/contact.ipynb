{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aabd71ce",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import isaacgym\n",
    "import isaacgymenvs\n",
    "from isaacgymenvs.utils.reformat import omegaconf_to_dict, print_dict\n",
    "from isaacgymenvs.utils.utils import set_np_formatting, set_seed\n",
    "from isaacgymenvs.utils.rlgames_utils import RLGPUEnv, RLGPUAlgoObserver, get_rlgames_env_creator\n",
    "\n",
    "from rl_games.common import env_configurations, vecenv\n",
    "from rl_games.torch_runner import Runner\n",
    "from rl_games.algos_torch import model_builder\n",
    "\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428e96d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = OmegaConf.load(\"../isaacgymenvs/cfg/config.yaml\")\n",
    "cfg.task_name = \"TrifingerNYU\"\n",
    "cfg.num_envs = 1\n",
    "cfg.task = OmegaConf.load(\"../isaacgymenvs/cfg/task/TrifingerNYU.yaml\")\n",
    "cfg.headless = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33738f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = cfg.sim_device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d7bae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_env_thunk(**kwargs):\n",
    "    envs = isaacgymenvs.make(\n",
    "            cfg.seed, \n",
    "            cfg.task_name, \n",
    "            cfg.task.env.numEnvs, \n",
    "            cfg.sim_device,\n",
    "            cfg.rl_device,\n",
    "            cfg.graphics_device_id,\n",
    "            cfg.headless,\n",
    "            cfg.multi_gpu,\n",
    "            cfg.capture_video,\n",
    "            cfg.force_render,\n",
    "            cfg,\n",
    "            **kwargs,\n",
    "        )\n",
    "    return envs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dbdd9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "envs = create_env_thunk()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adeb9ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from isaacgym.torch_utils import *\n",
    "\n",
    "def bmv(mat: torch.Tensor, vec: torch.Tensor):\n",
    "    return torch.einsum('bij, bj -> bi', mat, vec)\n",
    "\n",
    "def quat2mat(quat: torch.Tensor):\n",
    "    def _quat2mat(x, y, z, w):\n",
    "        x2, y2, z2 = x**2, y**2, z**2\n",
    "        wx, wy, wz = w*x, w*y, w*z\n",
    "        xy, xz, yz = x*y, x*z, y*z\n",
    "        rotation_matrix = torch.stack([\n",
    "            1-2*y2-2*z2, 2*(xy-wz), 2*(xz+wy),\n",
    "            2*(xy+wz), 1-2*x2-2*z2, 2*(yz-wx),\n",
    "            2*(xz-wy), 2*(yz+wx), 1-2*x2-2*y2]\n",
    "        )\n",
    "        return rotation_matrix.view(3, 3)\n",
    "    \n",
    "    x, y, z, w = torch.unbind(quat, dim=-1)\n",
    "    \n",
    "    return torch.vmap(_quat2mat)(x, y, z, w)\n",
    "\n",
    "def local2world(\n",
    "    local_frame_pose: torch.Tensor,\n",
    "    position_local: torch.Tensor\n",
    "):\n",
    "    local_frame_pos = local_frame_pose[:, 0:3]\n",
    "    local_frame_orn = local_frame_pose[:, 3:7]\n",
    "    rot = quat2mat(local_frame_orn)\n",
    "    \n",
    "    position_world = local_frame_pos + bmv(rot, position_local)\n",
    "\n",
    "    return position_world\n",
    "\n",
    "def world2local(\n",
    "    local_frame_pose: torch.Tensor,\n",
    "    position_world: torch.Tensor\n",
    "):\n",
    "    local_frame_pos = local_frame_pose[:, 0:3]\n",
    "    local_frame_orn = local_frame_pose[:, 3:7]\n",
    "    rot = quat2mat(local_frame_orn)\n",
    "    rot_inv = torch.transpose(rot, 1, 2)\n",
    "    \n",
    "    position_local = -bmv(rot_inv, local_frame_pos) + bmv(rot_inv, position_world)\n",
    "\n",
    "    return position_local\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c554ca88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get fingertip states\n",
    "N = 500\n",
    "action_buffer = torch.zeros(N, 9).to(device)\n",
    "ftip_pos_buffer = torch.zeros(N, 3, 3).to(device)\n",
    "ftip_pos_local_buffer = torch.zeros(N, 3, 3).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2055321e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in range(N):\n",
    "    q = envs._dof_position\n",
    "    dq = envs._dof_velocity\n",
    "    \n",
    "    fingertip_state = envs._rigid_body_state[:, envs._fingertip_indices]\n",
    "    fingertip_position = fingertip_state[:, :, 0:3]\n",
    "    ftip_pos_buffer[n] = fingertip_position[0]\n",
    "    \n",
    "    object_pose = envs._object_state_history[0][:, 0:7]\n",
    "    object_pos = object_pose[:, 0:3]\n",
    "    pos_diff = object_pos.repeat(1, 3) - fingertip_position.reshape(cfg.num_envs, 9)\n",
    "    \n",
    "    for i in range(3):\n",
    "        ftip_pos_local_buffer[n, i] = world2local(object_pose, fingertip_position[:, i, :])\n",
    "    \n",
    "    max_abs_val = torch.max(torch.abs(pos_diff))\n",
    "    normalized_vec = pos_diff / max_abs_val\n",
    "    action = 2 * normalized_vec - 1\n",
    "\n",
    "    action_buffer[n] = action[0]\n",
    "    obs, rwds, resets, info = envs.step(action)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2654a4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cube_contact_normals(ftip_pos, threshold=0.0435):\n",
    "    batch_size = len(ftip_pos)\n",
    "    contact_normals = torch.zeros(batch_size, 3)\n",
    "        \n",
    "    _, max_indices = torch.max(torch.abs(ftip_pos), dim=1)\n",
    "    max_values = torch.squeeze(torch.gather(ftip_pos, 1, max_indices.unsqueeze(1)))\n",
    "\n",
    "    mask_pos = (torch.abs(max_values) <= threshold) * (max_values > 0)\n",
    "    mask_neg = (torch.abs(max_values) <= threshold) * (max_values < 0)\n",
    "\n",
    "    contact_normals[mask_pos, max_indices[mask_pos]] = 1.0\n",
    "    contact_normals[mask_neg, max_indices[mask_neg]] = -1.0\n",
    "    \n",
    "    return contact_normals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8cea6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "ftip_pos = ftip_pos_local_buffer[:, 0, :]\n",
    "contact_normals = get_cube_contact_normals(ftip_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aca008f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
