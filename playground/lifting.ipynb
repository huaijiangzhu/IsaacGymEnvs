{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137ae555",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aabd71ce",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import isaacgym\n",
    "import isaacgymenvs\n",
    "from isaacgymenvs.utils.reformat import omegaconf_to_dict, print_dict\n",
    "from isaacgymenvs.utils.utils import set_np_formatting, set_seed\n",
    "from isaacgymenvs.utils.rlgames_utils import RLGPUEnv, RLGPUAlgoObserver, get_rlgames_env_creator\n",
    "\n",
    "from rl_games.common import env_configurations, vecenv\n",
    "from rl_games.torch_runner import Runner\n",
    "from rl_games.algos_torch import model_builder\n",
    "\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from vecrobotics import *\n",
    "from fista import QP, FISTA, ForceQP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428e96d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = OmegaConf.load(\"../isaacgymenvs/cfg/config.yaml\")\n",
    "cfg.task_name = \"TrifingerNYU\"\n",
    "cfg.num_envs = 1\n",
    "cfg.task = OmegaConf.load(\"../isaacgymenvs/cfg/task/TrifingerNYU.yaml\")\n",
    "cfg.task.env.command_mode = \"fingertip_diff_force\"\n",
    "cfg.headless = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d7bae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_env_thunk(**kwargs):\n",
    "    envs = isaacgymenvs.make(\n",
    "            cfg.seed, \n",
    "            cfg.task_name, \n",
    "            cfg.task.env.numEnvs, \n",
    "            cfg.sim_device,\n",
    "            cfg.rl_device,\n",
    "            cfg.graphics_device_id,\n",
    "            cfg.headless,\n",
    "            cfg.multi_gpu,\n",
    "            cfg.capture_video,\n",
    "            cfg.force_render,\n",
    "            cfg,\n",
    "            **kwargs,\n",
    "        )\n",
    "    return envs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b84736",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = cfg.sim_device\n",
    "envs = create_env_thunk()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d858ff54",
   "metadata": {},
   "outputs": [],
   "source": [
    "lifting_data = np.load(\"data/lifting.npz\", allow_pickle=True)[\"data\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c554ca88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get fingertip states\n",
    "envs.reset_idx(torch.arange(cfg.num_envs))\n",
    "N = 570\n",
    "action_buffer = torch.zeros(N, 18).to(device)\n",
    "ftip_pos_buffer = torch.zeros(N, 3, 3).to(device)\n",
    "ftip_pos_local_buffer = torch.zeros(N, 3, 3).to(device)\n",
    "object_pose_buffer = torch.zeros(N, 7).to(device)\n",
    "\n",
    "q_buffer = torch.zeros(N, 9).to(device)\n",
    "dq_buffer = torch.zeros(N, 9).to(device)\n",
    "obs, rwds, resets, info = envs.step(torch.zeros(cfg.num_envs, 18))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2055321e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in range(N):\n",
    "    q = envs._dof_position\n",
    "    dq = envs._dof_velocity\n",
    "    q_buffer[n] = q[0]\n",
    "    dq_buffer[n] = dq[0]\n",
    "    \n",
    "    fingertip_state = envs._rigid_body_state[:, envs._fingertip_indices]\n",
    "    fingertip_position = fingertip_state[:, :, 0:3]\n",
    "    ftip_pos_buffer[n] = fingertip_position[0]\n",
    "    \n",
    "    object_pose = envs._object_state_history[0][:, 0:7]\n",
    "    object_pose_buffer[n] = object_pose[0]\n",
    "\n",
    "    for i in range(3):\n",
    "        ftip_pos_local_buffer[n, i] = world2local(object_pose, fingertip_position[:, i, :])\n",
    "        \n",
    "    ftip_pos_des = torch.tensor(lifting_data[20 * n]['policy']['controller']['ft_pos_des'], dtype=torch.float32).to(device)\n",
    "    action = torch.zeros(cfg.num_envs, 18)\n",
    "    action[:, :9] = ftip_pos_des.view(cfg.num_envs, 9) - fingertip_position.reshape(cfg.num_envs, 9)\n",
    "     \n",
    "    action_buffer[n] = action[0]\n",
    "    obs, rwds, resets, info = envs.step(action)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2654a4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cube_contact_normals(ftip_pos, threshold=0.0435):\n",
    "    batch_size = len(ftip_pos)\n",
    "    contact_normals = torch.zeros(batch_size, 3).to(ftip_pos.device)\n",
    "        \n",
    "    _, max_indices = torch.max(torch.abs(ftip_pos), dim=1)\n",
    "    max_values = torch.squeeze(torch.gather(ftip_pos, 1, max_indices.unsqueeze(1)))\n",
    "\n",
    "    mask_pos = (torch.abs(max_values) <= threshold) * (max_values > 0)\n",
    "    mask_neg = (torch.abs(max_values) <= threshold) * (max_values < 0)\n",
    "\n",
    "    # contact normal points to the same direction as the contact force, hence into the object\n",
    "    contact_normals[mask_pos, max_indices[mask_pos]] = -1.0\n",
    "    contact_normals[mask_neg, max_indices[mask_neg]] = 1.0\n",
    "    \n",
    "    return contact_normals\n",
    "\n",
    "def get_contact_frame_orn(contact_normals: torch.Tensor):\n",
    "    # get the orientation of the contact frames expressed in the object frame\n",
    "    z_axis = contact_normals\n",
    "    zero_indices = torch.argmax(torch.eq(z_axis, 0).int(), dim=1)\n",
    "    y_axis = torch.eye(3).to(z_axis.device)[zero_indices]\n",
    "    x_axis = torch.cross(y_axis, z_axis)\n",
    "    y_axis = torch.cross(z_axis, x_axis) # this makes sure if z is all zero, then orn is a zero matrix\n",
    "    orn = torch.stack((x_axis, y_axis, z_axis), dim=2)\n",
    "    return orn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb63af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_batches, _ = object_pose_buffer.shape\n",
    "num_vars = 9\n",
    "num_eqc = 1\n",
    "A = torch.zeros(num_batches, num_eqc, num_vars)\n",
    "b = torch.zeros(num_batches, num_eqc)\n",
    "rho = 0 # rho = 0 supresss eqc Ax + b = 0\n",
    "lb = -10 * torch.ones(num_batches, num_vars)\n",
    "ub = 10 * torch.ones(num_batches, num_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd2c972",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = ftip_pos_local_buffer.view(-1, 3)\n",
    "contact_normals = get_cube_contact_normals(p)\n",
    "R = get_contact_frame_orn(contact_normals)\n",
    "R_stacked = R.transpose(1, 2).reshape(-1, 9, 3)\n",
    "Q1 = R_stacked @ R_stacked.transpose(1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c0ffcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pxR = vec2skew_sym_mat(p) @ R\n",
    "pxR_stacked = pxR.transpose(1, 2).reshape(-1, 9, 3)\n",
    "Q2 = pxR_stacked @ pxR_stacked.transpose(1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9bccd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = Q1 + 200 * Q2\n",
    "\n",
    "# for Q == 0, hence R1, R2, R3 == 0, fill the diagnoal of Q with ones. This produces f == 0\n",
    "reshaped_tensor = Q.view(num_batches, -1)\n",
    "diagonal_elements_zero = torch.all(reshaped_tensor[:, ::num_vars+1] == 0, dim=1)\n",
    "mask = diagonal_elements_zero[:, None].repeat(1, num_vars)\n",
    "diag_idx = torch.arange(num_vars)\n",
    "Q[:, diag_idx, diag_idx] = Q[:, diag_idx, diag_idx].masked_fill_(mask, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56633283",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = torch.tensor([0, 0, 9.81]).repeat(num_batches, 1).to(device)\n",
    "object_orn = quat2mat(object_pose_buffer[:, 3:])\n",
    "g_local = bmv(object_orn, g)\n",
    "m = 1\n",
    "q = -2 * m * bmv(R_stacked, g_local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adce8b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = ForceQP(num_batches, num_vars, friction_coeff=1.0, device=device)\n",
    "prob.set_data(Q, q, lb, ub)\n",
    "solver = FISTA(prob, device=device)\n",
    "max_it = 100\n",
    "for i in range(max_it):\n",
    "    solver.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262b90dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "forces = solver.prob.yk\n",
    "total_force = bmv(R_stacked.transpose(1,2), forces)\n",
    "total_torque = bmv(pxR_stacked.transpose(1,2), forces)\n",
    "force_norm = torch.norm(total_force, dim=1)\n",
    "torque_norm = torch.norm(total_torque, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ef453d",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = 304\n",
    "t2 = 350\n",
    "t3 = 150\n",
    "t = t3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
