{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b7257a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aabd71ce",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import isaacgym\n",
    "import isaacgymenvs\n",
    "from isaacgymenvs.utils.reformat import omegaconf_to_dict, print_dict\n",
    "from isaacgymenvs.utils.utils import set_np_formatting, set_seed\n",
    "from isaacgymenvs.utils.rlgames_utils import RLGPUEnv, RLGPUAlgoObserver, get_rlgames_env_creator\n",
    "\n",
    "from rl_games.common import env_configurations, vecenv\n",
    "from rl_games.torch_runner import Runner\n",
    "from rl_games.algos_torch import model_builder\n",
    "\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from vecrobotics import *\n",
    "from fista import QP, FISTA, ForceQP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428e96d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = OmegaConf.load(\"../isaacgymenvs/cfg/config.yaml\")\n",
    "cfg.task_name = \"TrifingerNYU\"\n",
    "cfg.num_envs = 1\n",
    "cfg.task = OmegaConf.load(\"../isaacgymenvs/cfg/task/TrifingerNYU.yaml\")\n",
    "cfg.task.env.command_mode = \"fingertip_diff_force\"\n",
    "cfg.headless = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d7bae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_env_thunk(**kwargs):\n",
    "    envs = isaacgymenvs.make(\n",
    "            cfg.seed, \n",
    "            cfg.task_name, \n",
    "            cfg.task.env.numEnvs, \n",
    "            cfg.sim_device,\n",
    "            cfg.rl_device,\n",
    "            cfg.graphics_device_id,\n",
    "            cfg.headless,\n",
    "            cfg.multi_gpu,\n",
    "            cfg.capture_video,\n",
    "            cfg.force_render,\n",
    "            cfg,\n",
    "            **kwargs,\n",
    "        )\n",
    "    return envs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b84736",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = cfg.sim_device\n",
    "envs = create_env_thunk()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d858ff54",
   "metadata": {},
   "outputs": [],
   "source": [
    "lifting_data = np.load(\"data/lifting.npz\", allow_pickle=True)[\"data\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c554ca88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get ftip states\n",
    "envs.reset_idx(torch.arange(cfg.num_envs))\n",
    "N = 570\n",
    "action_buffer = torch.zeros(N, 18).to(device)\n",
    "ftip_pos_buffer = torch.zeros(N, 3, 3).to(device)\n",
    "ftip_pos_local_buffer = torch.zeros(N, 3, 3).to(device)\n",
    "object_pose_buffer = torch.zeros(N, 7).to(device)\n",
    "contact_normals_buffer = []\n",
    "\n",
    "q_buffer = torch.zeros(N, 9).to(device)\n",
    "dq_buffer = torch.zeros(N, 9).to(device)\n",
    "obs, rwds, resets, info = envs.step(torch.zeros(cfg.num_envs, 18))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945f5b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cube_contact_normals(ftip_pos, threshold=0.0435):\n",
    "    batch_size = len(ftip_pos)\n",
    "    contact_normals = torch.zeros(batch_size, 3).to(ftip_pos.device)\n",
    "        \n",
    "    _, max_indices = torch.max(torch.abs(ftip_pos), dim=1)\n",
    "    max_values = torch.squeeze(torch.gather(ftip_pos, 1, max_indices.unsqueeze(1)))\n",
    "\n",
    "    mask_pos = (torch.abs(max_values) <= threshold) * (max_values > 0)\n",
    "    mask_neg = (torch.abs(max_values) <= threshold) * (max_values < 0)\n",
    "\n",
    "    # contact normal points to the same direction as the contact force, hence into the object\n",
    "    contact_normals[mask_pos, max_indices[mask_pos]] = -1.0\n",
    "    contact_normals[mask_neg, max_indices[mask_neg]] = 1.0\n",
    "    \n",
    "    return contact_normals\n",
    "\n",
    "def get_contact_frame_orn(contact_normals: torch.Tensor):\n",
    "    # get the orientation of the contact frames expressed in the object frame\n",
    "    z_axis = contact_normals\n",
    "    zero_indices = torch.argmax(torch.eq(z_axis, 0).int(), dim=1)\n",
    "    y_axis = torch.eye(3).to(z_axis.device)[zero_indices]\n",
    "    x_axis = torch.cross(y_axis, z_axis, dim=1)\n",
    "    y_axis = torch.cross(z_axis, x_axis, dim=1) # this makes sure if z is all zero, then orn is a zero matrix\n",
    "    orn = torch.stack((x_axis, y_axis, z_axis), dim=2)\n",
    "    return orn\n",
    "\n",
    "def hstacked_SO3_transform(mat, vec):\n",
    "    batch_size, d1, d2 = mat.shape\n",
    "    stack_size = d2 // 3\n",
    "    transformed = torch.zeros_like(vec)\n",
    "    for i in range(stack_size):\n",
    "        selection = torch.zeros_like(vec)\n",
    "        selection[:, 3*i:3*(i+1)] = 1\n",
    "        transformed[:, 3*i:3*(i+1)] = bmv(mat, vec * selection)\n",
    "    return transformed\n",
    "\n",
    "def get_force_qp_data(ftip_pos, object_pose, mg, weights=[1, 200, 1e-4]):\n",
    "    # get ftip positin in the object frame\n",
    "    batch_size, num_ftip, _ = ftip_pos.shape\n",
    "    p = world2local(object_pose.repeat_interleave(3, dim=0), \n",
    "                    ftip_pos.view(-1, 3))\n",
    "    contact_normals = get_cube_contact_normals(p)\n",
    "    R = get_contact_frame_orn(contact_normals)\n",
    "    R_vstacked = R.transpose(1, 2).reshape(-1, 3 * num_ftip, 3)\n",
    "    Q1 = R_vstacked @ R_vstacked.transpose(1, 2)\n",
    "    \n",
    "    pxR = vec2skew_sym_mat(p) @ R\n",
    "    pxR_vstacked = pxR.transpose(1, 2).reshape(-1, 3 * num_ftip, 3)\n",
    "    Q2 = pxR_vstacked @ pxR_vstacked.transpose(1, 2)\n",
    "    \n",
    "    w1, w2, w3 = weights\n",
    "    Q = w1 * Q1 + w2 * Q2 + w3 * torch.eye(3 * num_ftip).repeat(batch_size, 1, 1).to(Q1.device)\n",
    "\n",
    "    # for Q == 0, hence R1, R2, R3 == 0, fill the diagnoal of Q with ones. This produces f == 0\n",
    "    reshaped_tensor = Q.view(num_batches, -1)\n",
    "    diagonal_elements_zero = torch.all(reshaped_tensor[:, ::num_vars+1] == 0, dim=1)\n",
    "    mask = diagonal_elements_zero[:, None].repeat(1, num_vars)\n",
    "    diag_idx = torch.arange(num_vars)\n",
    "    Q[:, diag_idx, diag_idx] = Q[:, diag_idx, diag_idx].masked_fill_(mask, 1)\n",
    "    \n",
    "    object_orn = quat2mat(object_pose[:, 3:])\n",
    "    mg_local = bmv(object_orn.transpose(1,2), mg)\n",
    "    q = -2 * bmv(R_vstacked, mg_local)\n",
    "    \n",
    "    return Q, q, R_vstacked, pxR_vstacked, contact_normals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2055321e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# construct force QP\n",
    "num_batches = cfg.num_envs\n",
    "num_vars = 9\n",
    "lb = -10 * torch.ones(num_batches, num_vars)\n",
    "ub = 10 * torch.ones(num_batches, num_vars)\n",
    "mg = torch.tensor([0, 0, 9.81]).repeat(num_batches, 1).to(device)\n",
    "\n",
    "prob = ForceQP(num_batches, num_vars, friction_coeff=1.0, device=device)\n",
    "solver = FISTA(prob, device=device)\n",
    "max_it = 50\n",
    "\n",
    "for n in range(N):\n",
    "    q = envs._dof_position\n",
    "    dq = envs._dof_velocity\n",
    "    q_buffer[n] = q[0]\n",
    "    dq_buffer[n] = dq[0]\n",
    "    \n",
    "    ftip_state = envs._rigid_body_state[:, envs._fingertip_indices]\n",
    "    ftip_pos = ftip_state[:, :, 0:3]\n",
    "    ftip_pos_buffer[n] = ftip_pos[0]\n",
    "    \n",
    "    object_pose = envs._object_state_history[0][:, 0:7]\n",
    "    object_orn = quat2mat(object_pose[:, 3:])\n",
    "    object_pose_buffer[n] = object_pose[0]\n",
    "\n",
    "    for i in range(3):\n",
    "        ftip_pos_local_buffer[n, i] = world2local(object_pose, ftip_pos[:, i, :])\n",
    "        \n",
    "    # set up force qp\n",
    "    Q, q, R_vstacked, pxR_vstacked, contact_normals = get_force_qp_data(ftip_pos, object_pose, mg)    \n",
    "    prob.set_data(Q, q, lb, ub)\n",
    "    solver.reset()\n",
    "    for i in range(max_it):\n",
    "        solver.step()\n",
    "    ftip_force_contact_frame = solver.prob.yk.clone()\n",
    "    contact_normals_buffer.append(contact_normals)\n",
    "    \n",
    "    # convert force to the world frame\n",
    "    R = R_vstacked.reshape(-1, 3, 3).transpose(1, 2)\n",
    "    ftip_force_object_frame = stacked_bmv(R, ftip_force_contact_frame)\n",
    "    ftip_force_des = stacked_bmv(object_orn.repeat(3, 1, 1), ftip_force_object_frame)\n",
    "    ftip_pos_des = torch.tensor(lifting_data[20 * n]['policy']['controller']['ft_pos_des'], dtype=torch.float32).to(device)\n",
    "    \n",
    "    action = torch.zeros(cfg.num_envs, 18)\n",
    "    action[:, :9] = ftip_pos_des.view(cfg.num_envs, 9) - ftip_pos.reshape(cfg.num_envs, 9)\n",
    "    if len(contact_normals.nonzero()) == 3:\n",
    "        action[:, 9:] = ftip_force_des\n",
    "     \n",
    "    action_buffer[n] = action[0]\n",
    "    obs, rwds, resets, info = envs.step(action)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
